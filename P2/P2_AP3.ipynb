{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2_AP3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "exfjsDksxkjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!rm -rf /content/imagenes\n",
        "!unzip /content/drive/My\\ Drive/Colab\\ Notebooks/imagenes -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2hFfI5C7JXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Terminar de rellenar este bloque con lo que vaya haciendo falta\n",
        "\n",
        "# Importar librerías necesarias\n",
        "import numpy as np\n",
        "import keras\n",
        "import keras.utils as np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "# Importar el optimizador a usar\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Importar modelos y capas específicas que se van a usar\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import backend as K\n",
        "# Importar el modelo ResNet50 y su respectiva función de preprocesamiento,\n",
        "# que es necesario pasarle a las imágenes para usar este modelo\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "\n",
        "# Importar el optimizador a usar\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "#########################################################################\n",
        "################## FUNCIÓN PARA LEER LAS IMÁGENES #######################\n",
        "#########################################################################\n",
        "\n",
        "# Dado un fichero train.txt o test.txt y el path donde se encuentran los\n",
        "# ficheros y las imágenes, esta función lee las imágenes\n",
        "# especificadas en ese fichero y devuelve las imágenes en un vector y\n",
        "# sus clases en otro.\n",
        "\n",
        "def leerImagenes(vec_imagenes, path):\n",
        "  clases = np.array([img.split('/')[0] for img in vec_imagenes])\n",
        "  imagenes = np.array([img_to_array(load_img(path + \"/\" + img,\n",
        "                                             target_size = (224, 224)))\n",
        "                       for img in vec_imagenes])\n",
        "  return imagenes, clases\n",
        "\n",
        "#########################################################################\n",
        "############# FUNCIÓN PARA CARGAR EL CONJUNTO DE DATOS ##################\n",
        "#########################################################################\n",
        "\n",
        "# Usando la función anterior, y dado el path donde se encuentran las\n",
        "# imágenes y los archivos \"train.txt\" y \"test.txt\", devuelve las\n",
        "# imágenes y las clases de train y test para usarlas con keras\n",
        "# directamente.\n",
        "\n",
        "def cargarDatos(path):\n",
        "  # Cargamos los ficheros\n",
        "  train_images = np.loadtxt(path + \"/train.txt\", dtype = str)\n",
        "  test_images = np.loadtxt(path + \"/test.txt\", dtype = str)\n",
        "\n",
        "  # Leemos las imágenes con la función anterior\n",
        "  train, train_clases = leerImagenes(train_images, path)\n",
        "  test, test_clases = leerImagenes(test_images, path)\n",
        "\n",
        "  # Pasamos los vectores de las clases a matrices\n",
        "  # Para ello, primero pasamos las clases a números enteros\n",
        "  clases_posibles = np.unique(np.copy(train_clases))\n",
        "  for i in range(len(clases_posibles)):\n",
        "    train_clases[train_clases == clases_posibles[i]] = i\n",
        "    test_clases[test_clases == clases_posibles[i]] = i\n",
        "\n",
        "  # Después, usamos la función to_categorical()\n",
        "  train_clases = np_utils.to_categorical(train_clases, 200)\n",
        "  test_clases = np_utils.to_categorical(test_clases, 200)\n",
        "\n",
        "  # Barajar los datos\n",
        "  train_perm = np.random.permutation(len(train))\n",
        "  train = train[train_perm]\n",
        "  train_clases = train_clases[train_perm]\n",
        "\n",
        "  test_perm = np.random.permutation(len(test))\n",
        "  test = test[test_perm]\n",
        "  test_clases = test_clases[test_perm]\n",
        "\n",
        "  return train, train_clases, test, test_clases\n",
        "\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "######## FUNCIÓN PARA OBTENER EL ACCURACY DEL CONJUNTO DE TEST ##########\n",
        "#########################################################################\n",
        "\n",
        "# Esta función devuelve el accuracy de un modelo, definido como el\n",
        "# porcentaje de etiquetas bien predichas frente al total de etiquetas.\n",
        "# Como parámetros es necesario pasarle el vector de etiquetas verdaderas\n",
        "# y el vector de etiquetas predichas, en el formato de keras (matrices\n",
        "# donde cada etiqueta ocupa una fila, con un 1 en la posición de la clase\n",
        "# a la que pertenece y 0 en las demás).\n",
        "\n",
        "def calcularAccuracy(labels, preds):\n",
        "  labels = np.argmax(labels, axis = 1)\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "\n",
        "  accuracy = sum(labels == preds)/len(labels)\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "#########################################################################\n",
        "## FUNCIÓN PARA PINTAR LA PÉRDIDA Y EL ACCURACY EN TRAIN Y VALIDACIÓN ###\n",
        "#########################################################################\n",
        "\n",
        "# Esta función pinta dos gráficas, una con la evolución de la función\n",
        "# de pérdida en el conjunto de train y en el de validación, y otra\n",
        "# con la evolución del accuracy en el conjunto de train y en el de\n",
        "# validación. Es necesario pasarle como parámetro el historial\n",
        "# del entrenamiento del modelo (lo que devuelven las funciones\n",
        "# fit() y fit_generator()).\n",
        "\n",
        "def mostrarEvolucion(hist):\n",
        "\n",
        "  loss = hist.history['loss']\n",
        "  val_loss = hist.history['val_loss']\n",
        "  plt.plot(loss)\n",
        "  plt.plot(val_loss)\n",
        "  plt.legend(['Training loss', 'Validation loss'])\n",
        "  plt.show()\n",
        "\n",
        "  acc = hist.history['acc']\n",
        "  val_acc = hist.history['val_acc']\n",
        "  plt.plot(acc)\n",
        "  plt.plot(val_acc)\n",
        "  plt.legend(['Training accuracy', 'Validation accuracy'])\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"## Usar ResNet50 preentrenada en ImageNet como un extractor de características\"\"\"\n",
        "\n",
        "# Definir un objeto de la clase ImageDataGenerator para train y otro para test\n",
        "# con sus respectivos argumentos.\n",
        "\n",
        "\n",
        "# Definir el modelo ResNet50 (preentrenado en ImageNet y sin la última capa).\n",
        "\n",
        "\n",
        "# Extraer las características las imágenes con el modelo anterior.\n",
        "\n",
        "\n",
        "# Las características extraídas en el paso anterior van a ser la entrada\n",
        "# de un pequeño modelo de dos capas Fully Conected, donde la última será la que\n",
        "# nos clasifique las clases de Caltech-UCSD (200 clases). De esta forma, es\n",
        "# como si hubiéramos fijado todos los parámetros de ResNet50 y estuviésemos\n",
        "# entrenando únicamente las capas añadidas. Definir dicho modelo.\n",
        "# A completar: definición del modelo, del optimizador y compilación y\n",
        "# entrenamiento del modelo.\n",
        "# En la función fit() puedes usar el argumento validation_split\n",
        "\n",
        "\n",
        "\n",
        "def compile(model):\n",
        "    optEj3 = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=optEj3,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "def entrenamiento(model, x_train, y_train, batch_size, epochs):\n",
        "    # Entrenamos el modelo\n",
        "    historial = model.fit(x_train, y_train,\n",
        "             batch_size = batch_size,\n",
        "             epochs = epochs,\n",
        "             verbose = 1,\n",
        "             validation_split = 0.1)\n",
        "\n",
        "    return historial\n",
        "\n",
        "def entrenamiento_datagen(model, datagen, x_train, y_train, batch_size, epochs):\n",
        "    historial = model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size, subset = 'training'),\n",
        "       epochs = epochs,\n",
        "       steps_per_epoch = len(x_train)*0.9/batch_size,\n",
        "       verbose = 1,\n",
        "       validation_data = datagen.flow(x_train, y_train, batch_size = batch_size, subset = 'validation'),\n",
        "       validation_steps = len(x_train)*0.1/batch_size)\n",
        "\n",
        "    return historial\n",
        "\n",
        "def prediccion(model, datagen, x):\n",
        "    return model.predict_generator(datagen.flow(x, batch_size = 1, shuffle = False), steps = len(x))\n",
        "\n",
        "def evaluacion(model, x_test, y_test):\n",
        "    return model.evaluate(x_test, y_test)\n",
        "\n",
        "def evaluacion_datagen(model, datagen, x_test, y_test):\n",
        "    return model.evaluate_generator(datagen.flow(x_test, y_test, batch_size = 1, shuffle = False), steps = len(x_test))\n",
        "\n",
        "\n",
        "def definicionModelo():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024, activation = 'relu', input_shape = (2048, )))\n",
        "    model.add(Dense(200, activation = 'softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def ej3_1(batch_size, epochs):\n",
        "    print(\"\\n\\nCargando imágenes...\")\n",
        "    x_train, y_train, x_test, y_test = cargarDatos(\"./imagenes\")\n",
        "    print(\"\\nTodo OK.\")\n",
        "\n",
        "    datagen_train = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "    datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "\n",
        "    resnet50 = ResNet50(weights='imagenet', include_top = False, pooling = \"avg\", input_shape = (224, 224, 3))\n",
        "\n",
        "    print(\"\\nExtraigo características...\")\n",
        "    features_train = prediccion(resnet50, datagen_train, x_train)\n",
        "    features_test = prediccion(resnet50, datagen_test, x_test)\n",
        "    print(\"\\nCaracterísticas extraídas.\")\n",
        "    model = definicionModelo()\n",
        "    compile(model)\n",
        "    print(\"\\nEntrenando...\")\n",
        "    historial = entrenamiento(model, x_train, y_train, batch_size, epochs)\n",
        "    print(\"\\nFin de entrenamiento, evaluando...\")\n",
        "    score = evaluacion(model, x_test, y_test)\n",
        "    mostrarEvolucion(historial)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "\n",
        "\n",
        "ej3_1(batch_size, epochs)\n",
        "input(\"Fin del apartado 1, pulsa Enter\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx3aXx4wwuyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"## Reentrenar ResNet50 (fine tunning)\"\"\"\n",
        "\n",
        "def definicionModeloApartado2(x):\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.7)(x)\n",
        "    last = Dense(200, activation='softmax')(x)\n",
        "    return last\n",
        "\n",
        "def ej3_2(batch_size, epochs):\n",
        "    print(\"\\n\\nCargando imágenes...\")\n",
        "    x_train, y_train, x_test, y_test = cargarDatos(\"./imagenes\")\n",
        "    print(\"\\nTodo OK.\")\n",
        "\n",
        "    datagen_train = ImageDataGenerator(preprocessing_function = preprocess_input, validation_split = 0.1)\n",
        "    datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "\n",
        "    resnet50 = ResNet50(weights='imagenet', include_top = False, pooling = \"avg\", input_shape = (224, 224, 3))\n",
        "\n",
        "    last = definicionModeloApartado2(resnet50.output)\n",
        "    new_model = Model(inputs = resnet50.input, outputs = last)\n",
        "\n",
        "    print(\"\\nCompilando el modelo con el optimizador...\")\n",
        "    compile(new_model)\n",
        "    print(\"\\nEntrenando...\")\n",
        "    historial = entrenamiento_datagen(new_model, datagen_train, x_train, y_train, batch_size, epochs)\n",
        "    print(\"\\nFin de entrenamiento, evaluando...\")\n",
        "    score = evaluacion_datagen(new_model, datagen_test, x_test, y_test)\n",
        "\n",
        "    mostrarEvolucion(historial)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "\n",
        "\n",
        "ej3_2(batch_size, epochs)\n",
        "input(\"Fin del apartado 2, pulsa Enter\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}